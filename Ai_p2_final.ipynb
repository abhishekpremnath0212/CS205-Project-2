{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ai p2 final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def distance(a,b,values):#calulating euclidean distance\n",
        "    dist = 0\n",
        "    for i in values:\n",
        "        dist += math.pow(a[i]-b[i],2)\n",
        "    return math.sqrt(dist)\n",
        "\n",
        "def NN(a,b,values):#calculating nearest neighbor\n",
        "    val = []\n",
        "    for i in a:\n",
        "        dist = distance(i,b,values)\n",
        "        val.append([dist,i[0]])\n",
        "    val.sort(key=operator.itemgetter(0))\n",
        "    return val[0][1]"
      ],
      "metadata": {
        "id": "y8sKVT5wdeLP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_acc(mat,current_feat,feature,choice):#calcuating accuracy with a set of features\n",
        "\n",
        "    freq = 0\n",
        "    current = list(current_feat[:])\n",
        "    if choice == 1:\n",
        "        current.append(feature)\n",
        "    else:\n",
        "        current.remove(feature)\n",
        "\n",
        "    for k in range(0, len(mat)):\n",
        "        train = mat[:]\n",
        "        test = train.pop(k)\n",
        "        group = NN(train,test,current)\n",
        "        if test[0] == group:\n",
        "            freq += 1\n",
        "    acc = freq / float(len(mat))\n",
        "    return acc"
      ],
      "metadata": {
        "id": "6vP_IC1udksC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_selection(mat):#forward selection\n",
        "    global xx\n",
        "    global yy\n",
        "    xx=[]\n",
        "    yy=[]\n",
        "    ff = []\n",
        "    fa = 0\n",
        "    current_features = []\n",
        "    feature_size = len(mat[0])\n",
        "    accuracies = []\n",
        "    inc=0\n",
        "    for i in range(1,feature_size):\n",
        "        added_feature = -1\n",
        "        ba = 0\n",
        "\n",
        "        for j in range(1,feature_size):\n",
        "            if j not in current_features:\n",
        "                acc = calculate_acc(mat,current_features,j,1)\n",
        "                print( \"Using feature(s) [\"+str(j)+\"] acc is \"+str(acc))\n",
        "                if acc > ba:\n",
        "                    ba = acc\n",
        "                    added_feature = j\n",
        "\n",
        "        if added_feature != -1:\n",
        "            current_features.append(added_feature)\n",
        "            print(\"\\nlevel \"+str(i)+\" feature: \"+ str(added_feature) + \" added beacuse it has the highest accuracy\")\n",
        "            print(\"Best accuracy:\"+str(ba)+\" with features \"+str(current_features))\n",
        "            xx.append(\"lvl \"+str(inc))\n",
        "            inc+=1\n",
        "            yy.append(ba)\n",
        "            \n",
        "            accuracies.append(ba)#appending accuracies\n",
        "        if ba > fa:#updating best accuracy\n",
        "            ff = current_features[:]\n",
        "            fa = ba\n",
        "    print(\"\\n\")\n",
        "    print(\"Best feature subset is: \"+str(ff))\n",
        "    print(\"Best accuracy is: \"+str(fa))"
      ],
      "metadata": {
        "id": "Ul8L3rAWdknb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_elimination(mat):#backward elimination\n",
        "    ii=0\n",
        "    global xx\n",
        "    global yy\n",
        "    ff = []\n",
        "    fa = 0\n",
        "    current_features = list(range(1,len(mat[0])))\n",
        "    feature_size = len(mat[0])\n",
        "    accuracies = []\n",
        "    for i in range(1, feature_size):\n",
        "        del_feature = -1\n",
        "        ba = 0\n",
        "        for j in range(1, feature_size):\n",
        "            if j in current_features:\n",
        "                acc = calculate_acc(mat, current_features,j,2)\n",
        "                print(\"Using feature(s) [\" + str(j) + \"] acc is \" + str(acc))\n",
        "                if acc > ba:#updating best accuary\n",
        "                    ba = acc\n",
        "                    del_feature = j\n",
        "\n",
        "        if del_feature != -1:\n",
        "            current_features.remove(del_feature)\n",
        "            print(\"\\nlevel \" + str(i) + \" feature: \" + str(del_feature)+\" with accuracy:\" + str(ba)+\" was removed\")\n",
        "            accuracies.append(ba)\n",
        "            xx.append(\"lvl \"+str(ii))\n",
        "            ii+=1\n",
        "            yy.append(ba)\n",
        "        if ba > fa:\n",
        "            ff = current_features[:]\n",
        "            fa = ba\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"Best feature subset is: \"+str(ff))\n",
        "    print(\"Best accuracy is: \"+str(fa))\n",
        "    "
      ],
      "metadata": {
        "id": "P-mn21X4dkYr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':#driver code\n",
        "    file = \"CS205_SP_2022_SMALLtestdata__79.txt\"#text file can be changed for a different dataset\n",
        "    with open(file) as f:\n",
        "        data = f.readlines()\n",
        "    row = []\n",
        "    mat = []\n",
        "    data = [x.strip() for x in data]\n",
        "    for line in data:\n",
        "        values = re.split(\" +\",line)\n",
        "        for v in values:#converting to 2D matrix\n",
        "            val = float(decimal.Decimal(v))\n",
        "            row.append(val)\n",
        "        mat.append(row)\n",
        "        row = []\n",
        "\n",
        "    print(\"Choose Algorithm\\n 1.Forward Search\\n 2.Backward Elimination\")\n",
        "    n = int(input(\"Enter your choice: \"))\n",
        "    \n",
        "    start_time = time.time()\n",
        "    if n==1:\n",
        "        forward_selection(mat)\n",
        "    elif n==2:\n",
        "        backward_elimination(mat)\n",
        "    else:\n",
        "      print(\"Invalid Choice\")\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSkO9oqddkWA",
        "outputId": "1c134aa9-dc97-4216-b906-f7ad256260ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose Algorithm\n",
            " 1.Forward Search\n",
            " 2.Backward Elimination\n",
            "Enter your choice: 1\n",
            "Using feature(s) [1] acc is 0.6866666666666666\n",
            "Using feature(s) [2] acc is 0.71\n",
            "Using feature(s) [3] acc is 0.7133333333333334\n",
            "Using feature(s) [4] acc is 0.6833333333333333\n",
            "Using feature(s) [5] acc is 0.69\n",
            "Using feature(s) [6] acc is 0.7066666666666667\n",
            "Using feature(s) [7] acc is 0.7033333333333334\n",
            "Using feature(s) [8] acc is 0.8233333333333334\n",
            "Using feature(s) [9] acc is 0.7233333333333334\n",
            "Using feature(s) [10] acc is 0.68\n",
            "\n",
            "level 1 feature: 8 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.8233333333333334 with features [8]\n",
            "Using feature(s) [1] acc is 0.7733333333333333\n",
            "Using feature(s) [2] acc is 0.9666666666666667\n",
            "Using feature(s) [3] acc is 0.8366666666666667\n",
            "Using feature(s) [4] acc is 0.7966666666666666\n",
            "Using feature(s) [5] acc is 0.8333333333333334\n",
            "Using feature(s) [6] acc is 0.82\n",
            "Using feature(s) [7] acc is 0.81\n",
            "Using feature(s) [9] acc is 0.8566666666666667\n",
            "Using feature(s) [10] acc is 0.8\n",
            "\n",
            "level 2 feature: 2 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.9666666666666667 with features [8, 2]\n",
            "Using feature(s) [1] acc is 0.8833333333333333\n",
            "Using feature(s) [3] acc is 0.94\n",
            "Using feature(s) [4] acc is 0.94\n",
            "Using feature(s) [5] acc is 0.93\n",
            "Using feature(s) [6] acc is 0.91\n",
            "Using feature(s) [7] acc is 0.9233333333333333\n",
            "Using feature(s) [9] acc is 0.9533333333333334\n",
            "Using feature(s) [10] acc is 0.9033333333333333\n",
            "\n",
            "level 3 feature: 9 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.9533333333333334 with features [8, 2, 9]\n",
            "Using feature(s) [1] acc is 0.8633333333333333\n",
            "Using feature(s) [3] acc is 0.91\n",
            "Using feature(s) [4] acc is 0.88\n",
            "Using feature(s) [5] acc is 0.8533333333333334\n",
            "Using feature(s) [6] acc is 0.88\n",
            "Using feature(s) [7] acc is 0.92\n",
            "Using feature(s) [10] acc is 0.86\n",
            "\n",
            "level 4 feature: 7 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.92 with features [8, 2, 9, 7]\n",
            "Using feature(s) [1] acc is 0.8266666666666667\n",
            "Using feature(s) [3] acc is 0.8566666666666667\n",
            "Using feature(s) [4] acc is 0.8366666666666667\n",
            "Using feature(s) [5] acc is 0.84\n",
            "Using feature(s) [6] acc is 0.8533333333333334\n",
            "Using feature(s) [10] acc is 0.8233333333333334\n",
            "\n",
            "level 5 feature: 3 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.8566666666666667 with features [8, 2, 9, 7, 3]\n",
            "Using feature(s) [1] acc is 0.8166666666666667\n",
            "Using feature(s) [4] acc is 0.8266666666666667\n",
            "Using feature(s) [5] acc is 0.8033333333333333\n",
            "Using feature(s) [6] acc is 0.8566666666666667\n",
            "Using feature(s) [10] acc is 0.8066666666666666\n",
            "\n",
            "level 6 feature: 6 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.8566666666666667 with features [8, 2, 9, 7, 3, 6]\n",
            "Using feature(s) [1] acc is 0.8566666666666667\n",
            "Using feature(s) [4] acc is 0.8233333333333334\n",
            "Using feature(s) [5] acc is 0.8033333333333333\n",
            "Using feature(s) [10] acc is 0.7966666666666666\n",
            "\n",
            "level 7 feature: 1 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.8566666666666667 with features [8, 2, 9, 7, 3, 6, 1]\n",
            "Using feature(s) [4] acc is 0.7833333333333333\n",
            "Using feature(s) [5] acc is 0.8066666666666666\n",
            "Using feature(s) [10] acc is 0.7933333333333333\n",
            "\n",
            "level 8 feature: 5 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.8066666666666666 with features [8, 2, 9, 7, 3, 6, 1, 5]\n",
            "Using feature(s) [4] acc is 0.7633333333333333\n",
            "Using feature(s) [10] acc is 0.7833333333333333\n",
            "\n",
            "level 9 feature: 10 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.7833333333333333 with features [8, 2, 9, 7, 3, 6, 1, 5, 10]\n",
            "Using feature(s) [4] acc is 0.7566666666666667\n",
            "\n",
            "level 10 feature: 4 added beacuse it has the highest accuracy\n",
            "Best accuracy:0.7566666666666667 with features [8, 2, 9, 7, 3, 6, 1, 5, 10, 4]\n",
            "\n",
            "\n",
            "Best feature subset is: [8, 2]\n",
            "Best accuracy is: 0.9666666666666667\n",
            "--- 8.137334108352661 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gcf().autofmt_xdate()#data visualization\n",
        "plt.xlabel(\"Level of Search\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.bar(xx,yy)\n",
        "\n",
        "plt.xticks(rotation = 45)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "CSl4m_3JdkS4",
        "outputId": "68287f7b-21a2-44cc-a581-a04abfc65903"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}